# Agentic-customer-support-framework-designed-with-LangGraph-Streaming-and-RAG-facilitated-by-LLMs

# Application title: 
Agentic customer support smart platform using LangGraph with Streaming, and RAG supported by LLMs 

# Target: 
The main goals of this project are to make an end to end Agentic LLM pipeline with LangGraph, streaming, and RAG powered by LLMs. This workflow considers:
•	Identify customer questions
•	Find proper paths using sentimental analysis
•	Advance unresolved questions to human agents
•	Assign customer questions according to customized AI agents such as Tech, Billing, General.                                                                                                                        
•	Facilitate streaming and non-streaming processing
•	Apply Retrieval-Augmented Generation (RAG) for knowledge based on results.
•	Sustain a real-world focused system layout

# Libraries and Frameworks:
•	Python | jupyter notebook | 
•	LangChain | ChatOpenAI (LLMs) | LangGraph
•	Vector database
•	Prompt engineering
•	Streaming processing   Workflow 
•	Memory Storage for pipeline 

# Notable features:
•	Agentic AI workflow with LangGraph   
•	Context focused routing
•	RAG enabled results
•	Human inspection
•	Streaming and non-streaming operations
•	End-to-end case testing
•	Operationally optimized framework
•	Workflow supported examples (Tech Support, Billing, General Inquiry)

# Closing remarks: 
I have clearly shown a fully functional Agentic AI system. It supports: 
•	 End to end workflow with memory
•	 LLM Processing
•	RAG supported access
•	Real time monitoring
•	Logic supported decision flow
•	Supervised action
•	Using LangGraph to make end to end workflow.

